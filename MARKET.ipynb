{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdOMAIPUVTX7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"your_file.csv\")  # Use actual file path\n",
        "\n",
        "# Ensure numbers are properly parsed\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice', 'sQty',\n",
        "                'ltq', 'avgPrice', 'quotes', 'ttq', 'totalBuyQt', 'totalSellQ', 'ttv',\n",
        "                'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 1. üîé Large Deals: Top 2% by total traded value or volume\n",
        "large_deals = df[(df['ttv'] > df['ttv'].quantile(0.98)) | (df['VolumeC'] > df['VolumeC'].quantile(0.98))]\n",
        "\n",
        "# 2. üìà Strong Buy Pressure: Bid > Ask, high last traded quantity\n",
        "strong_buys = df[(df['bQty'] > df['sQty']) & (df['ltq'] > 10000)]\n",
        "\n",
        "# 3. üîÑ OI Build-up: High OI + OI change\n",
        "oi_build = df[(df['OI'] > df['OI'].quantile(0.9)) & (df['CHNGOI'] > 0)]\n",
        "\n",
        "# 4. üöÄ Trending Stocks: Strong price momentum\n",
        "trending_up = df[df['change'] > 5]  # >5% gain\n",
        "trending_down = df[df['change'] < -5]  # >5% loss\n",
        "\n",
        "# 5. üìä Combined Signal: Intersection of large volume + buy pressure + OI build-up\n",
        "smart_signals = large_deals.merge(strong_buys, on='symbol').merge(oi_build, on='symbol')\n",
        "\n",
        "# Show relevant insights\n",
        "print(\"Top Large Deals:\\n\", large_deals[['symbol', 'ttv', 'VolumeC', 'last']].sort_values(by='ttv', ascending=False).head())\n",
        "print(\"\\nStrong Buy Pressure:\\n\", strong_buys[['symbol', 'bQty', 'sQty', 'ltq']].head())\n",
        "print(\"\\nOI Build-Up:\\n\", oi_build[['symbol', 'OI', 'CHNGOI']].head())\n",
        "print(\"\\nTrending Stocks:\\n\", trending_up[['symbol', 'change']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === Load File ===\n",
        "import pandas as pd\n",
        "\n",
        "# === Load File ===\n",
        "file_path = \"/content/extracted/18-07-2025_0.txt\"  # Replace this if the filename is different\n",
        "\n",
        "# Define column names based on the data structure\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "# Load the CSV without a header and assign the defined column names\n",
        "df = pd.read_csv(file_path, header=None, names=columns)\n",
        "\n",
        "\n",
        "# === Convert Required Columns ===\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "#df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df = df.sort_values('ltt').groupby('symbol').tail(1).reset_index(drop=True)\n",
        "\n",
        "# === Compute Derived Fields ===\n",
        "df['Change%'] = ((df['last'] - df['open']) / df['open']) * 100\n",
        "\n",
        "# === Sentiment Classification ===\n",
        "def classify_sentiment(row):\n",
        "    if row['change'] > 0 and row['CHNGOI'] > 0:\n",
        "        return \"Bullish Buildup\"\n",
        "    elif row['change'] < 0 and row['CHNGOI'] > 0:\n",
        "        return \"Bearish Buildup\"\n",
        "    elif row['change'] > 0 and row['CHNGOI'] < 0:\n",
        "        return \"Short Covering\"\n",
        "    elif row['change'] < 0 and row['CHNGOI'] < 0:\n",
        "        return \"Long Unwinding\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "df['Sentiment'] = df.apply(classify_sentiment, axis=1)\n",
        "\n",
        "# === üî• Strongest / ‚ùÑÔ∏è Weakest ===\n",
        "strongest = df.sort_values(by='Change%', ascending=False).head(10)\n",
        "weakest = df.sort_values(by='Change%').head(10)\n",
        "\n",
        "# === üìâ Sector-wise Summary ===\n",
        "if 'stock_name' in df.columns:\n",
        "    sector_summary = df.groupby('stock_name')['Sentiment'].value_counts().unstack(fill_value=0)\n",
        "else:\n",
        "    sector_summary = pd.DataFrame()\n",
        "\n",
        "# === üìÖ Market Outlook ===\n",
        "bulls = (df['Sentiment'] == 'Bullish Buildup').sum()\n",
        "bears = (df['Sentiment'] == 'Bearish Buildup').sum()\n",
        "short_covering = (df['Sentiment'] == 'Short Covering').sum()\n",
        "unwinding = (df['Sentiment'] == 'Long Unwinding').sum()\n",
        "\n",
        "net_strength = (bulls + short_covering) - (bears + unwinding)\n",
        "outlook = \"üìà Bullish Bias\" if net_strength > 0 else \"üìâ Bearish Bias\" if net_strength < 0 else \"‚ûñ Neutral\"\n",
        "\n",
        "# === üè¶ Large Deals Detection ===\n",
        "high_volume = df['VolumeC'].quantile(0.98)\n",
        "high_ttv = df['ttv'].quantile(0.98)\n",
        "large_deals = df[(df['VolumeC'] >= high_volume) | (df['ttv'] >= high_ttv)]\n",
        "large_deals = large_deals.sort_values(by='ttv', ascending=False).head(10)\n",
        "\n",
        "# === üß≤ Large Investor Buy/Sell Pressure ===\n",
        "buy_dominant = df[(df['bQty'] > df['sQty']) & (df['ltq'] > 10000)].sort_values(by='bQty', ascending=False).head(10)\n",
        "sell_dominant = df[(df['sQty'] > df['bQty']) & (df['ltq'] > 10000)].sort_values(by='sQty', ascending=False).head(10)\n",
        "\n",
        "# === üìä Print Results ===\n",
        "print(\"\\nüî• Strongest Stocks:\\n\", strongest[['symbol', 'Change%', 'VolumeC', 'OI', 'Sentiment']])\n",
        "print(\"\\n‚ùÑÔ∏è Weakest Stocks:\\n\", weakest[['symbol', 'Change%', 'VolumeC', 'OI', 'Sentiment']])\n",
        "print(\"\\nüìÖ Predicted Market Outlook:\", outlook)\n",
        "print(f\"Net Strength Score: {net_strength} (Bulls + SC vs Bears + UW)\")\n",
        "\n",
        "if not sector_summary.empty:\n",
        "    print(\"\\nüìâ Sector-wise Sentiment Summary:\\n\", sector_summary)\n",
        "\n",
        "print(\"\\nüí∞ Top Large Deals (High Volume/TTv):\\n\", large_deals[['symbol', 'last', 'ttv', 'VolumeC', 'Change%']])\n",
        "print(\"\\nüè¶ Potential Large Buyer Activity:\\n\", buy_dominant[['symbol', 'bQty', 'sQty', 'ltq', 'last']])\n",
        "print(\"\\nüîª Potential Large Seller Activity:\\n\", sell_dominant[['symbol', 'bQty', 'sQty', 'ltq', 'last']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STI5WSN-WE_i",
        "outputId": "46fa48c0-c405-4093-80e3-18f35702d3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî• Strongest Stocks:\n",
            "          symbol  Change%  VolumeC  OI Sentiment\n",
            "0    1.1!533202      inf      0.0 NaN   Neutral\n",
            "5    1.1!533896      inf      0.0 NaN   Neutral\n",
            "432  1.1!524031      inf      0.0 NaN   Neutral\n",
            "438  1.1!511441      inf      0.0 NaN   Neutral\n",
            "542  1.1!530765      inf      0.0 NaN   Neutral\n",
            "609  1.1!540728      inf      0.0 NaN   Neutral\n",
            "6    1.1!538119      inf      0.0 NaN   Neutral\n",
            "11   1.1!532468      inf      0.0 NaN   Neutral\n",
            "257  1.1!502937      inf      0.0 NaN   Neutral\n",
            "12   1.1!532662      inf      0.0 NaN   Neutral\n",
            "\n",
            "‚ùÑÔ∏è Weakest Stocks:\n",
            "          symbol  Change%    VolumeC  OI Sentiment\n",
            "588  1.1!530291   -100.0    5644.05 NaN   Neutral\n",
            "593  1.1!530617   -100.0  318000.00 NaN   Neutral\n",
            "587  1.1!531280   -100.0    5617.24 NaN   Neutral\n",
            "540  1.1!506543   -100.0     124.85 NaN   Neutral\n",
            "534  1.1!513642   -100.0   30095.10 NaN   Neutral\n",
            "603  1.1!513544   -100.0    5969.92 NaN   Neutral\n",
            "630  1.1!519174   -100.0   10471.63 NaN   Neutral\n",
            "628  1.1!511451   -100.0    6326.32 NaN   Neutral\n",
            "533  1.1!531812   -100.0   27062.03 NaN   Neutral\n",
            "517  1.1!533482   -100.0   13345.56 NaN   Neutral\n",
            "\n",
            "üìÖ Predicted Market Outlook: ‚ûñ Neutral\n",
            "Net Strength Score: 0 (Bulls + SC vs Bears + UW)\n",
            "\n",
            "üìâ Sector-wise Sentiment Summary:\n",
            " Sentiment                       Neutral\n",
            "stock_name                             \n",
            "3B BLACKBIO DX LIMITED                1\n",
            "3M INDIA LIMITED                      1\n",
            "3P LAND HOLDINGS LTD                  1\n",
            "63 MOONS TECHNOLOGIES LIMITED         1\n",
            "A-1 LIMITED                           1\n",
            "...                                 ...\n",
            "ZODIAC CLOTHING CO. LTD.              1\n",
            "ZODIAC VENTURES LIMITED               1\n",
            "ZUARI AGRO CHEMICALS LIMITED          1\n",
            "ZUARI INDUSTRIES LIMITED              1\n",
            "ZYDUS LIFESCIENCES LIMITED            1\n",
            "\n",
            "[2332 rows x 1 columns]\n",
            "\n",
            "üí∞ Top Large Deals (High Volume/TTv):\n",
            "           symbol    last       ttv   VolumeC   Change%\n",
            "428   1.1!519612  107.37  99961.47  99961.47  0.000000\n",
            "1874  1.1!500464  148.50  99327.30  99327.30 -1.818182\n",
            "1823  1.1!502448    1.74  99083.30  99083.30  3.571429\n",
            "442   1.1!520131   38.90  98048.00  98048.00 -9.302868\n",
            "89    1.1!531795  472.95  97779.95  97779.95  0.520723\n",
            "1903  1.1!512297   14.10  97390.76  97390.76 -1.052632\n",
            "1124  1.1!526043   61.20  97127.74  97127.74 -2.702703\n",
            "1112  1.1!526492  130.15  97046.50  97046.50  1.362928\n",
            "485   1.1!531319   39.47  96746.03  96746.03 -6.023810\n",
            "463   1.1!517077   96.64  96737.85  96737.85 -0.010347\n",
            "\n",
            "üè¶ Potential Large Buyer Activity:\n",
            "           symbol     bQty    sQty     ltq   last\n",
            "108   1.1!533090  3828502       0   11500   1.21\n",
            "1528  1.1!532022  1570277  567389  334000   0.68\n",
            "1035  1.1!531395   825938  127377  463428   6.33\n",
            "1966  1.1!505336   810038       0   61559   1.34\n",
            "1123  1.1!526709    53336    2800   21414  10.86\n",
            "\n",
            "üîª Potential Large Seller Activity:\n",
            "           symbol   bQty      sQty     ltq   last\n",
            "1181  1.1!540614   2700  10166588  115246   0.58\n",
            "1273  1.1!511557      1   5666495   16317   8.33\n",
            "1333  1.1!511116      0   2005596   25839   0.44\n",
            "1669  1.1!511012      0   1581561   57404   1.14\n",
            "1310  1.1!511700      0    471571  242638   0.63\n",
            "1822  1.1!505523      0    393041   30266   0.49\n",
            "1830  1.1!500389      0    376669   20549  15.17\n",
            "1116  1.1!524632   2605    244852   19876  21.57\n",
            "1929  1.1!501314   3000    164456   11863   0.73\n",
            "1172  1.1!523722  25000     29575   25020   8.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === Load File ===\n",
        "file_path = \"/content/extracted/18-07-2025_0.txt\"  # Replace this if the filename is different\n",
        "\n",
        "# Define column names based on the data structure\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "# Load the CSV without a header and assign the defined column names\n",
        "df = pd.read_csv(file_path, header=None, names=columns)\n",
        "\n",
        "# === Convert Required Columns ===\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "#df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df = df.sort_values('ltt').groupby('symbol').tail(1).reset_index(drop=True)\n",
        "\n",
        "# === Compute Derived Fields ===\n",
        "df['Change%'] = ((df['last'] - df['open']) / df['open']) * 100\n",
        "\n",
        "# === Sentiment Classification ===\n",
        "def classify_sentiment(row):\n",
        "    if row['change'] > 0 and row['CHNGOI'] > 0:\n",
        "        return \"Bullish Buildup\"\n",
        "    elif row['change'] < 0 and row['CHNGOI'] > 0:\n",
        "        return \"Bearish Buildup\"\n",
        "    elif row['change'] > 0 and row['CHNGOI'] < 0:\n",
        "        return \"Short Covering\"\n",
        "    elif row['change'] < 0 and row['CHNGOI'] < 0:\n",
        "        return \"Long Unwinding\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "df['Sentiment'] = df.apply(classify_sentiment, axis=1)\n",
        "\n",
        "# === üî• Strongest / ‚ùÑÔ∏è Weakest ===\n",
        "strongest = df.sort_values(by='Change%', ascending=False).head(10)\n",
        "weakest = df.sort_values(by='Change%').head(10)\n",
        "\n",
        "# === üìâ Sector-wise Summary ===\n",
        "if 'stock_name' in df.columns:\n",
        "    sector_summary = df.groupby('stock_name')['Sentiment'].value_counts().unstack(fill_value=0)\n",
        "else:\n",
        "    sector_summary = pd.DataFrame()\n",
        "\n",
        "# === üìÖ Market Outlook ===\n",
        "bulls = (df['Sentiment'] == 'Bullish Buildup').sum()\n",
        "bears = (df['Sentiment'] == 'Bearish Buildup').sum()\n",
        "short_covering = (df['Sentiment'] == 'Short Covering').sum()\n",
        "unwinding = (df['Sentiment'] == 'Long Unwinding').sum()\n",
        "\n",
        "net_strength = (bulls + short_covering) - (bears + unwinding)\n",
        "outlook = \"üìà Bullish Bias\" if net_strength > 0 else \"üìâ Bearish Bias\" if net_strength < 0 else \"‚ûñ Neutral\"\n",
        "\n",
        "# === üí∞ Large Deals Detection ===\n",
        "high_volume = df['VolumeC'].quantile(0.98)\n",
        "high_ttv = df['ttv'].quantile(0.98)\n",
        "large_deals = df[(df['VolumeC'] >= high_volume) | (df['ttv'] >= high_ttv)]\n",
        "large_deals = large_deals.sort_values(by='ttv', ascending=False).head(10)\n",
        "\n",
        "# === üè¶ Large Investor Buy/Sell Pressure ===\n",
        "buy_dominant = df[(df['bQty'] > df['sQty']) & (df['ltq'] > 10000)].sort_values(by='bQty', ascending=False).head(10)\n",
        "sell_dominant = df[(df['sQty'] > df['bQty']) & (df['ltq'] > 10000)].sort_values(by='sQty', ascending=False).head(10)\n",
        "\n",
        "# === üß≠ Market Pressure ===\n",
        "df['BuyPressure'] = (df['bQty'] > df['sQty']) & (df['ltq'] > 10000)\n",
        "df['SellPressure'] = (df['sQty'] > df['bQty']) & (df['ltq'] > 10000)\n",
        "buy_count = df['BuyPressure'].sum()\n",
        "sell_count = df['SellPressure'].sum()\n",
        "\n",
        "if buy_count > sell_count:\n",
        "    pressure = \"üü¢ Market Under Buy Pressure\"\n",
        "elif sell_count > buy_count:\n",
        "    pressure = \"üî¥ Market Under Sell Pressure\"\n",
        "else:\n",
        "    pressure = \"‚öñÔ∏è Balanced Pressure\"\n",
        "\n",
        "# === üìä Print Results ===\n",
        "print(\"\\nüî• Strongest Stocks:\\n\", strongest[['symbol', 'Change%', 'VolumeC', 'OI', 'Sentiment']])\n",
        "print(\"\\n‚ùÑÔ∏è Weakest Stocks:\\n\", weakest[['symbol', 'Change%', 'VolumeC', 'OI', 'Sentiment']])\n",
        "print(\"\\nüìÖ Predicted Market Outlook:\", outlook)\n",
        "print(f\"Net Strength Score: {net_strength} (Bulls + SC vs Bears + UW)\")\n",
        "\n",
        "if not sector_summary.empty:\n",
        "    print(\"\\nüìâ Sector-wise Sentiment Summary:\\n\", sector_summary)\n",
        "\n",
        "print(\"\\nüí∞ Top Large Deals (High Volume/TTv):\\n\", large_deals[['symbol', 'last', 'ttv', 'VolumeC', 'Change%']])\n",
        "print(\"\\nüè¶ Potential Large Buyer Activity:\\n\", buy_dominant[['symbol', 'bQty', 'sQty', 'ltq', 'last']])\n",
        "print(\"\\nüîª Potential Large Seller Activity:\\n\", sell_dominant[['symbol', 'bQty', 'sQty', 'ltq', 'last']])\n",
        "print(\"\\nüß≠ Market Pressure Analysis:\")\n",
        "print(f\"Buy Dominant Stocks: {buy_count}\")\n",
        "print(f\"Sell Dominant Stocks: {sell_count}\")\n",
        "print(f\"Overall Market Pressure: {pressure}\")\n",
        "\n",
        "\n",
        "# === üìä Composite Market Strength Score Strategy ===\n",
        "advancers = df[df['change'] > 0].shape[0]\n",
        "decliners = df[df['change'] < 0].shape[0]\n",
        "adr = advancers / (decliners + 1)\n",
        "\n",
        "# VWAP Bias\n",
        "df['VWAP'] = df['ttv'] / df['VolumeC']\n",
        "df['VWAP_Bias'] = df['last'] > df['VWAP']\n",
        "vwap_bias_count = df['VWAP_Bias'].sum()\n",
        "\n",
        "# Composite Score\n",
        "score = 0\n",
        "if net_strength > 0: score += 1\n",
        "if adr > 1: score += 1\n",
        "if vwap_bias_count > len(df) * 0.6: score += 1\n",
        "if bulls > bears: score += 1\n",
        "if short_covering > unwinding: score += 1\n",
        "\n",
        "print(\"\\nüß† Composite Strategy Signals:\")\n",
        "print(f\"Advance/Decline Ratio (ADR): {adr:.2f}\")\n",
        "print(f\"Stocks Above VWAP: {vwap_bias_count}/{len(df)}\")\n",
        "print(f\"Net Sentiment Strength Score: {net_strength}\")\n",
        "print(f\"Composite Signal Score: {score}/5\")\n",
        "\n",
        "# Final Prediction\n",
        "if score >= 4:\n",
        "    print(\"üìà High Probability Bullish Day Tomorrow\")\n",
        "elif score <= 1:\n",
        "    print(\"üìâ High Probability Bearish Day Tomorrow\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Rangebound or Mixed Sentiment Expected Tomorrow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM2LREJOWwbf",
        "outputId": "0ac6d2e0-0f9a-4314-de10-02971e671790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî• Strongest Stocks:\n",
            "          symbol  Change%  VolumeC  OI Sentiment\n",
            "0    1.1!533202      inf      0.0 NaN   Neutral\n",
            "5    1.1!533896      inf      0.0 NaN   Neutral\n",
            "432  1.1!524031      inf      0.0 NaN   Neutral\n",
            "438  1.1!511441      inf      0.0 NaN   Neutral\n",
            "542  1.1!530765      inf      0.0 NaN   Neutral\n",
            "609  1.1!540728      inf      0.0 NaN   Neutral\n",
            "6    1.1!538119      inf      0.0 NaN   Neutral\n",
            "11   1.1!532468      inf      0.0 NaN   Neutral\n",
            "257  1.1!502937      inf      0.0 NaN   Neutral\n",
            "12   1.1!532662      inf      0.0 NaN   Neutral\n",
            "\n",
            "‚ùÑÔ∏è Weakest Stocks:\n",
            "          symbol  Change%    VolumeC  OI Sentiment\n",
            "588  1.1!530291   -100.0    5644.05 NaN   Neutral\n",
            "593  1.1!530617   -100.0  318000.00 NaN   Neutral\n",
            "587  1.1!531280   -100.0    5617.24 NaN   Neutral\n",
            "540  1.1!506543   -100.0     124.85 NaN   Neutral\n",
            "534  1.1!513642   -100.0   30095.10 NaN   Neutral\n",
            "603  1.1!513544   -100.0    5969.92 NaN   Neutral\n",
            "630  1.1!519174   -100.0   10471.63 NaN   Neutral\n",
            "628  1.1!511451   -100.0    6326.32 NaN   Neutral\n",
            "533  1.1!531812   -100.0   27062.03 NaN   Neutral\n",
            "517  1.1!533482   -100.0   13345.56 NaN   Neutral\n",
            "\n",
            "üìÖ Predicted Market Outlook: ‚ûñ Neutral\n",
            "Net Strength Score: 0 (Bulls + SC vs Bears + UW)\n",
            "\n",
            "üìâ Sector-wise Sentiment Summary:\n",
            " Sentiment                       Neutral\n",
            "stock_name                             \n",
            "3B BLACKBIO DX LIMITED                1\n",
            "3M INDIA LIMITED                      1\n",
            "3P LAND HOLDINGS LTD                  1\n",
            "63 MOONS TECHNOLOGIES LIMITED         1\n",
            "A-1 LIMITED                           1\n",
            "...                                 ...\n",
            "ZODIAC CLOTHING CO. LTD.              1\n",
            "ZODIAC VENTURES LIMITED               1\n",
            "ZUARI AGRO CHEMICALS LIMITED          1\n",
            "ZUARI INDUSTRIES LIMITED              1\n",
            "ZYDUS LIFESCIENCES LIMITED            1\n",
            "\n",
            "[2332 rows x 1 columns]\n",
            "\n",
            "üí∞ Top Large Deals (High Volume/TTv):\n",
            "           symbol    last       ttv   VolumeC   Change%\n",
            "428   1.1!519612  107.37  99961.47  99961.47  0.000000\n",
            "1874  1.1!500464  148.50  99327.30  99327.30 -1.818182\n",
            "1823  1.1!502448    1.74  99083.30  99083.30  3.571429\n",
            "442   1.1!520131   38.90  98048.00  98048.00 -9.302868\n",
            "89    1.1!531795  472.95  97779.95  97779.95  0.520723\n",
            "1903  1.1!512297   14.10  97390.76  97390.76 -1.052632\n",
            "1124  1.1!526043   61.20  97127.74  97127.74 -2.702703\n",
            "1112  1.1!526492  130.15  97046.50  97046.50  1.362928\n",
            "485   1.1!531319   39.47  96746.03  96746.03 -6.023810\n",
            "463   1.1!517077   96.64  96737.85  96737.85 -0.010347\n",
            "\n",
            "üè¶ Potential Large Buyer Activity:\n",
            "           symbol     bQty    sQty     ltq   last\n",
            "108   1.1!533090  3828502       0   11500   1.21\n",
            "1528  1.1!532022  1570277  567389  334000   0.68\n",
            "1035  1.1!531395   825938  127377  463428   6.33\n",
            "1966  1.1!505336   810038       0   61559   1.34\n",
            "1123  1.1!526709    53336    2800   21414  10.86\n",
            "\n",
            "üîª Potential Large Seller Activity:\n",
            "           symbol   bQty      sQty     ltq   last\n",
            "1181  1.1!540614   2700  10166588  115246   0.58\n",
            "1273  1.1!511557      1   5666495   16317   8.33\n",
            "1333  1.1!511116      0   2005596   25839   0.44\n",
            "1669  1.1!511012      0   1581561   57404   1.14\n",
            "1310  1.1!511700      0    471571  242638   0.63\n",
            "1822  1.1!505523      0    393041   30266   0.49\n",
            "1830  1.1!500389      0    376669   20549  15.17\n",
            "1116  1.1!524632   2605    244852   19876  21.57\n",
            "1929  1.1!501314   3000    164456   11863   0.73\n",
            "1172  1.1!523722  25000     29575   25020   8.17\n",
            "\n",
            "üß≠ Market Pressure Analysis:\n",
            "Buy Dominant Stocks: 5\n",
            "Sell Dominant Stocks: 13\n",
            "Overall Market Pressure: üî¥ Market Under Sell Pressure\n",
            "\n",
            "üß† Composite Strategy Signals:\n",
            "Advance/Decline Ratio (ADR): 0.61\n",
            "Stocks Above VWAP: 605/2332\n",
            "Net Sentiment Strength Score: 0\n",
            "Composite Signal Score: 0/5\n",
            "üìâ High Probability Bearish Day Tomorrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === Load Market Data ===\n",
        "file_path = \"18-07-2025_0.txt\"  # Change this to your input file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Convert numeric columns\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# === VWAP Bias ===\n",
        "df['VWAP'] = df['ttv'] / df['VolumeC']\n",
        "vwap_bias = (df['last'] > df['VWAP']).sum()\n",
        "vwap_score = 1 if vwap_bias > len(df) * 0.6 else 0\n",
        "\n",
        "# === Order Book Imbalance ===\n",
        "order_imbalance_score = 1 if (df['bQty'] > df['sQty']).sum() > len(df) * 0.6 else 0\n",
        "\n",
        "# === Smart Money Flow Index (SMFI Proxy) ===\n",
        "df['close_strength'] = df['last'] - df['open']\n",
        "smfi_score = 1 if df['close_strength'].mean() > 0 else 0\n",
        "\n",
        "# === Volume Profile Break Proxy ===\n",
        "df['Range'] = df['high'] - df['low']\n",
        "range_breaks = df[df['last'] >= df['high']]\n",
        "volume_break_score = 1 if len(range_breaks) > len(df) * 0.2 else 0\n",
        "\n",
        "# === Global Cue Input (mocked here, replace with real data if available) ===\n",
        "sgx_nifty_up = True\n",
        "usd_inr_weak = True\n",
        "global_score = 1 if sgx_nifty_up and usd_inr_weak else 0\n",
        "\n",
        "# === Composite Institutional Score ===\n",
        "total_score = vwap_score + order_imbalance_score + smfi_score + volume_break_score + global_score\n",
        "\n",
        "print(\"\\nüß† SMART INSTITUTIONAL MODEL SUMMARY:\")\n",
        "print(f\"VWAP Bias Score: {vwap_score}\")\n",
        "print(f\"Order Book Imbalance Score: {order_imbalance_score}\")\n",
        "print(f\"Smart Money Flow Proxy Score: {smfi_score}\")\n",
        "print(f\"Volume Breakout Score: {volume_break_score}\")\n",
        "print(f\"Global Cue Score: {global_score}\")\n",
        "print(f\"Total Score: {total_score}/5\")\n",
        "\n",
        "# === Final Prediction ===\n",
        "if total_score >= 4:\n",
        "    print(\"üìà Institutional Signal: STRONG BULLISH BIAS for Tomorrow\")\n",
        "elif total_score <= 1:\n",
        "    print(\"üìâ Institutional Signal: STRONG BEARISH BIAS for Tomorrow\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Institutional Signal: NEUTRAL or RANGEBOUND Market\")\n"
      ],
      "metadata": {
        "id": "oVoDoT5gXoh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === Load Market Data ===\n",
        "file_path = \"18-07-2025_0.txt\"  # Change this to your file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# === Convert numeric columns ===\n",
        "numeric_cols = [\n",
        "    'open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "    'sQty', 'ltq', 'avgPrice', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "    'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close'\n",
        "]\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# === VWAP Bias ===\n",
        "df['VWAP'] = df['ttv'] / df['VolumeC']\n",
        "vwap_bias = (df['last'] > df['VWAP']).sum()\n",
        "vwap_score = 1 if vwap_bias > len(df) * 0.6 else 0\n",
        "\n",
        "# === Order Book Imbalance (Smart Money Accumulation) ===\n",
        "order_imbalance_score = 1 if (df['bQty'] > df['sQty']).sum() > len(df) * 0.6 else 0\n",
        "\n",
        "# === Smart Money Flow Index (SMFI Proxy) ===\n",
        "df['close_strength'] = df['last'] - df['open']\n",
        "smfi_score = 1 if df['close_strength'].mean() > 0 else 0\n",
        "\n",
        "# === Volume Profile Breakout Proxy ===\n",
        "df['Range'] = df['high'] - df['low']\n",
        "range_breaks = df[df['last'] >= df['high']]\n",
        "volume_break_score = 1 if len(range_breaks) > len(df) * 0.2 else 0\n",
        "\n",
        "# === Global Cue Inputs (mock values for now) ===\n",
        "sgx_nifty_up = True         # ‚úÖ Replace with API input or manual toggle\n",
        "usd_inr_weak = True         # ‚úÖ Replace with actual data if needed\n",
        "global_score = 1 if sgx_nifty_up and usd_inr_weak else 0\n",
        "\n",
        "# === Composite Institutional Strength Score ===\n",
        "total_score = (\n",
        "    vwap_score +\n",
        "    order_imbalance_score +\n",
        "    smfi_score +\n",
        "    volume_break_score +\n",
        "    global_score\n",
        ")\n",
        "\n",
        "# === üìä Print Results ===\n",
        "print(\"\\nüß† SMART INSTITUTIONAL MODEL SUMMARY:\")\n",
        "print(f\"VWAP Bias Score: {vwap_score}\")\n",
        "print(f\"Order Book Imbalance Score: {order_imbalance_score}\")\n",
        "print(f\"Smart Money Flow Proxy Score: {smfi_score}\")\n",
        "print(f\"Volume Breakout Score: {volume_break_score}\")\n",
        "print(f\"Global Cue Score: {global_score}\")\n",
        "print(f\"‚û°Ô∏è Total Score: {total_score}/5\")\n",
        "\n",
        "# === Final Prediction ===\n",
        "if total_score >= 4:\n",
        "    print(\"üìà Institutional Signal: STRONG BULLISH BIAS for Tomorrow\")\n",
        "elif total_score <= 1:\n",
        "    print(\"üìâ Institutional Signal: STRONG BEARISH BIAS for Tomorrow\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Institutional Signal: NEUTRAL or RANGEBOUND Market\")\n"
      ],
      "metadata": {
        "id": "Ad9pF9q-X4XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    try:\n",
        "        # Specify no header and provide column names\n",
        "        df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "        df_list.append(df_temp)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "print(f\"\\nüìÅ Loaded {len(files)} files, Total rows: {len(df)}\")\n",
        "\n",
        "# === Convert numeric columns ===\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'quotes', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df = df.sort_values('ltt').groupby('symbol').tail(1).reset_index(drop=True)\n",
        "# === VWAP Bias ===\n",
        "df['VWAP'] = df['ttv'] / df['VolumeC']\n",
        "vwap_bias = (df['last'] > df['VWAP']).sum()\n",
        "vwap_score = 1 if vwap_bias > len(df) * 0.6 else 0\n",
        "\n",
        "# === Order Book Imbalance (Smart Money Accumulation) ===\n",
        "order_imbalance_score = 1 if (df['bQty'] > df['sQty']).sum() > len(df) * 0.6 else 0\n",
        "\n",
        "# === Smart Money Flow Index (SMFI Proxy) ===\n",
        "df['close_strength'] = df['last'] - df['open']\n",
        "smfi_score = 1 if df['close_strength'].mean() > 0 else 0\n",
        "\n",
        "# === Volume Profile Breakout Proxy ===\n",
        "df['Range'] = df['high'] - df['low']\n",
        "range_breaks = df[df['last'] >= df['high']]\n",
        "volume_break_score = 1 if len(range_breaks) > len(df) * 0.2 else 0\n",
        "\n",
        "# === Global Cue Inputs (mock values) ===\n",
        "sgx_nifty_up = True         # ‚úÖ Replace with API or real values\n",
        "usd_inr_weak = True\n",
        "global_score = 1 if sgx_nifty_up and usd_inr_weak else 0\n",
        "\n",
        "# === Composite Institutional Strength Score ===\n",
        "total_score = (\n",
        "    vwap_score +\n",
        "    order_imbalance_score +\n",
        "    smfi_score +\n",
        "    volume_break_score +\n",
        "    global_score\n",
        ")\n",
        "\n",
        "# === üìä Print Results ===\n",
        "print(\"\\nüß† SMART INSTITUTIONAL MODEL SUMMARY:\")\n",
        "print(f\"VWAP Bias Score: {vwap_score}\")\n",
        "print(f\"Order Book Imbalance Score: {order_imbalance_score}\")\n",
        "print(f\"Smart Money Flow Proxy Score: {smfi_score}\")\n",
        "print(f\"Volume Breakout Score: {volume_break_score}\")\n",
        "print(f\"Global Cue Score: {global_score}\")\n",
        "print(f\"‚û°Ô∏è Total Score: {total_score}/5\")\n",
        "\n",
        "# === Final Prediction ===\n",
        "if total_score >= 4:\n",
        "    print(\"üìà Institutional Signal: STRONG BULLISH BIAS for Tomorrow\")\n",
        "elif total_score <= 1:\n",
        "    print(\"üìâ Institutional Signal: STRONG BEARISH BIAS for Tomorrow\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Institutional Signal: NEUTRAL or RANGEBOUND Market\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNCHQ9XTYJkH",
        "outputId": "fa16fdd4-f252-4b97-c1e4-a057ab06fa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üìÅ Loaded 1 files, Total rows: 1574071\n",
            "\n",
            "üß† SMART INSTITUTIONAL MODEL SUMMARY:\n",
            "VWAP Bias Score: 0\n",
            "Order Book Imbalance Score: 0\n",
            "Smart Money Flow Proxy Score: 0\n",
            "Volume Breakout Score: 1\n",
            "Global Cue Score: 1\n",
            "‚û°Ô∏è Total Score: 2/5\n",
            "‚öñÔ∏è Institutional Signal: NEUTRAL or RANGEBOUND Market\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    try:\n",
        "        # Specify no header and provide column names\n",
        "        df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "        df_list.append(df_temp)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "print(f\"\\nüìÅ Loaded {len(files)} files, Total rows: {len(df)}\")\n",
        "\n",
        "# === Convert numeric columns ===\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'quotes', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'bPrice', 'sPrice', 'bQty', 'sQty', 'ltq', 'VolumeC']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# === Tick-based Buy/Sell Pressure ===\n",
        "df['delta_price'] = df['last'].diff()\n",
        "df['buy_volume'] = np.where(df['delta_price'] > 0, df['ltq'], 0)\n",
        "df['sell_volume'] = np.where(df['delta_price'] < 0, df['ltq'], 0)\n",
        "\n",
        "total_buy = df['buy_volume'].sum()\n",
        "total_sell = df['sell_volume'].sum()\n",
        "\n",
        "# === Order Imbalance ===\n",
        "df['order_imbalance'] = (df['bQty'] - df['sQty']) / (df['bQty'] + df['sQty'])\n",
        "net_order_imbalance = df['order_imbalance'].mean()\n",
        "\n",
        "# === Money Flow Index Proxy ===\n",
        "df['typical_price'] = (df['high'] + df['low'] + df['last']) / 3\n",
        "df['money_flow'] = df['typical_price'] * df['VolumeC']\n",
        "df['raw_flow'] = np.where(df['typical_price'] > df['typical_price'].shift(), df['money_flow'], -df['money_flow'])\n",
        "mfi_score = df['raw_flow'].rolling(window=14).sum().iloc[-1]\n",
        "\n",
        "# === Accumulation/Distribution ===\n",
        "df['clv'] = ((df['last'] - df['low']) - (df['high'] - df['last'])) / (df['high'] - df['low'])\n",
        "df['clv'] = df['clv'].fillna(0)\n",
        "df['ad_volume'] = df['clv'] * df['VolumeC']\n",
        "ad_trend = df['ad_volume'].cumsum().iloc[-1]\n",
        "\n",
        "# === Sentiment Decision ===\n",
        "print(\"\\nüí∞ MONEY FLOW SENTIMENT ANALYSIS:\")\n",
        "print(f\"Total Buy Volume: {total_buy}\")\n",
        "print(f\"Total Sell Volume: {total_sell}\")\n",
        "print(f\"Order Imbalance: {net_order_imbalance:.2f}\")\n",
        "print(f\"MFI Score (14-tick): {mfi_score:.2f}\")\n",
        "print(f\"Accumulation Trend: {ad_trend:.2f}\")\n",
        "\n",
        "if total_buy > total_sell and net_order_imbalance > 0.3 and mfi_score > 0:\n",
        "    print(\"üìà Money Flow Sentiment: STRONG BUYING\")\n",
        "elif total_sell > total_buy and net_order_imbalance < -0.3 and mfi_score < 0:\n",
        "    print(\"üìâ Money Flow Sentiment: STRONG SELLING\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Money Flow Sentiment: NEUTRAL / MIXED\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXJopEXvdFyw",
        "outputId": "218dfd06-1075-4075-887d-4178496f4a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üìÅ Loaded 1 files, Total rows: 1574071\n",
            "\n",
            "üí∞ MONEY FLOW SENTIMENT ANALYSIS:\n",
            "Total Buy Volume: 121055298\n",
            "Total Sell Volume: 1467798216\n",
            "Order Imbalance: -0.03\n",
            "MFI Score (14-tick): 271800312863.35\n",
            "Accumulation Trend: nan\n",
            "‚öñÔ∏è Money Flow Sentiment: NEUTRAL / MIXED\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:57: RuntimeWarning: invalid value encountered in accumulate\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    try:\n",
        "        # Specify no header and provide column names\n",
        "        df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "        df_list.append(df_temp)\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file}: {e}\")\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "print(f\"\\nüìÅ Loaded {len(files)} files, Total rows: {len(df)}\")\n",
        "\n",
        "# === Convert numeric columns ===\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'quotes', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# === Tick-based Buy/Sell Pressure ===\n",
        "df['delta_price'] = df['last'].diff()\n",
        "df['buy_volume'] = np.where(df['delta_price'] > 0, df['ltq'], 0)\n",
        "df['sell_volume'] = np.where(df['delta_price'] < 0, df['ltq'], 0)\n",
        "\n",
        "total_buy = df['buy_volume'].sum()\n",
        "total_sell = df['sell_volume'].sum()\n",
        "sentiment_ratio = total_buy / (total_sell + 1)\n",
        "\n",
        "# === Order Imbalance ===\n",
        "df['order_imbalance'] = (df['bQty'] - df['sQty']) / (df['bQty'] + df['sQty'])\n",
        "net_order_imbalance = df['order_imbalance'].mean()\n",
        "\n",
        "# === Money Flow Index Proxy ===\n",
        "df['typical_price'] = (df['high'] + df['low'] + df['last']) / 3\n",
        "df['money_flow'] = df['typical_price'] * df['VolumeC']\n",
        "df['raw_flow'] = np.where(df['typical_price'] > df['typical_price'].shift(), df['money_flow'], -df['money_flow'])\n",
        "mfi_score = df['raw_flow'].rolling(window=14).sum().iloc[-1]\n",
        "mfi_score_norm = np.log1p(abs(mfi_score)) * np.sign(mfi_score)\n",
        "\n",
        "# === Accumulation/Distribution ===\n",
        "df['range'] = (df['high'] - df['low']).replace(0, 0.0001)\n",
        "df['clv'] = ((df['last'] - df['low']) - (df['high'] - df['last'])) / df['range']\n",
        "df['clv'] = df['clv'].fillna(0)\n",
        "df['ad_volume'] = df['clv'] * df['VolumeC']\n",
        "ad_trend = df['ad_volume'].cumsum().iloc[-1]\n",
        "\n",
        "# === Sentiment Decision ===\n",
        "print(\"\\nüí∞ MONEY FLOW SENTIMENT ANALYSIS (Fixed):\")\n",
        "print(f\"Total Buy Volume: {total_buy}\")\n",
        "print(f\"Total Sell Volume: {total_sell}\")\n",
        "print(f\"Buy/Sell Sentiment Ratio: {sentiment_ratio:.3f}\")\n",
        "print(f\"Order Imbalance: {net_order_imbalance:.2f}\")\n",
        "print(f\"MFI Score (log-normalized): {mfi_score_norm:.2f}\")\n",
        "print(f\"Accumulation Trend: {ad_trend:.2f}\")\n",
        "\n",
        "if sentiment_ratio < 0.2 and net_order_imbalance < -0.2 and mfi_score < 0:\n",
        "    print(\"üìâ Money Flow Sentiment: STRONG SELLING\")\n",
        "elif sentiment_ratio > 0.7 and net_order_imbalance > 0.2 and mfi_score > 0:\n",
        "    print(\"üìà Money Flow Sentiment: STRONG BUYING\")\n",
        "else:\n",
        "    print(\"‚öñÔ∏è Money Flow Sentiment: NEUTRAL / MIXED\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncw3WprFd6eY",
        "outputId": "57f8b0ce-639b-4032-9558-a63df87bd106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üìÅ Loaded 1 files, Total rows: 1574071\n",
            "\n",
            "üí∞ MONEY FLOW SENTIMENT ANALYSIS (Fixed):\n",
            "Total Buy Volume: 121062525\n",
            "Total Sell Volume: 1468189820\n",
            "Buy/Sell Sentiment Ratio: 0.082\n",
            "Order Imbalance: -0.03\n",
            "MFI Score (log-normalized): 26.33\n",
            "Accumulation Trend: -1071038323623824.38\n",
            "‚öñÔ∏è Money Flow Sentiment: NEUTRAL / MIXED\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "\n",
        "# === Define Smart Money Time Windows ===\n",
        "opening_start = pd.to_datetime(\"09:15:00\").time()\n",
        "opening_end = pd.to_datetime(\"10:00:00\").time()\n",
        "closing_start = pd.to_datetime(\"14:45:00\").time()\n",
        "closing_end = pd.to_datetime(\"15:15:00\").time()\n",
        "\n",
        "df['time'] = df['ltt'].dt.time\n",
        "\n",
        "# === Filter for Opening & Closing Smart Money Zones ===\n",
        "df_opening = df[(df['time'] >= opening_start) & (df['time'] <= opening_end)]\n",
        "df_closing = df[(df['time'] >= closing_start) & (df['time'] <= closing_end)]\n",
        "\n",
        "# === Analyze Volume Clusters ===\n",
        "opening_volumes = df_opening.groupby('symbol')['ltq'].sum().sort_values(ascending=False)\n",
        "closing_volumes = df_closing.groupby('symbol')['ltq'].sum().sort_values(ascending=False)\n",
        "\n",
        "# === Print Top Smart Money Symbols ===\n",
        "print(\"\\n‚è≥ SMART MONEY ZONE ANALYSIS\")\n",
        "print(\"üîÅ Top 10 Opening Drive Volume Symbols (9:15‚Äì10:00):\")\n",
        "print(opening_volumes.head(10))\n",
        "\n",
        "print(\"\\nüîÅ Top 10 Closing Accumulation Symbols (14:45‚Äì15:15):\")\n",
        "print(closing_volumes.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGbWPaTnejzn",
        "outputId": "64e1e71b-80d6-4fb0-fc83-2bbbe825531f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "‚è≥ SMART MONEY ZONE ANALYSIS\n",
            "üîÅ Top 10 Opening Drive Volume Symbols (9:15‚Äì10:00):\n",
            "symbol\n",
            "1.1!540614    308581567\n",
            "1.1!531395     29447138\n",
            "1.1!511700     24605206\n",
            "1.1!511557     19984580\n",
            "1.1!506642     19560054\n",
            "1.1!505336     15645878\n",
            "1.1!511012      3075990\n",
            "1.1!512591      2275248\n",
            "1.1!517554      2080586\n",
            "1.1!524632      1723244\n",
            "Name: ltq, dtype: int64\n",
            "\n",
            "üîÅ Top 10 Closing Accumulation Symbols (14:45‚Äì15:15):\n",
            "symbol\n",
            "1.1!511700    4074456\n",
            "1.1!531395    3762176\n",
            "1.1!506642    3624649\n",
            "1.1!500389    2878862\n",
            "1.1!505336    1758443\n",
            "1.1!511557     968810\n",
            "1.1!540614     743519\n",
            "1.1!511012     513404\n",
            "1.1!524174     355666\n",
            "1.1!524632     238171\n",
            "Name: ltq, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "df['time'] = df['ltt'].dt.time\n",
        "\n",
        "# === Time Windows ===\n",
        "opening_start = pd.to_datetime(\"09:15:00\").time()\n",
        "opening_end = pd.to_datetime(\"10:00:00\").time()\n",
        "closing_start = pd.to_datetime(\"14:45:00\").time()\n",
        "closing_end = pd.to_datetime(\"15:15:00\").time()\n",
        "\n",
        "df_opening = df[(df['time'] >= opening_start) & (df['time'] <= opening_end)]\n",
        "df_closing = df[(df['time'] >= closing_start) & (df['time'] <= closing_end)]\n",
        "\n",
        "def detect_sentiment(group):\n",
        "    if len(group) < 2: return \"Insufficient\"\n",
        "    price_change = group['last'].iloc[-1] - group['last'].iloc[0]\n",
        "    avg_bqty = group['bQty'].mean()\n",
        "    avg_sqty = group['sQty'].mean()\n",
        "    if price_change > 0 and avg_bqty > avg_sqty:\n",
        "        return \"üìà Bullish\"\n",
        "    elif price_change < 0 and avg_sqty > avg_bqty:\n",
        "        return \"üìâ Bearish\"\n",
        "    else:\n",
        "        return \"‚öñÔ∏è Neutral\"\n",
        "\n",
        "# === Compute Volume & Sentiment ===\n",
        "opening_summary = (\n",
        "    df_opening.groupby('symbol')\n",
        "    .agg(total_volume=('ltq', 'sum'))\n",
        "    .sort_values('total_volume', ascending=False)\n",
        "    .head(10)\n",
        ")\n",
        "opening_summary['Sentiment'] = opening_summary.index.to_series().apply(\n",
        "    lambda sym: detect_sentiment(df_opening[df_opening['symbol'] == sym])\n",
        ")\n",
        "\n",
        "closing_summary = (\n",
        "    df_closing.groupby('symbol')\n",
        "    .agg(total_volume=('ltq', 'sum'))\n",
        "    .sort_values('total_volume', ascending=False)\n",
        "    .head(10)\n",
        ")\n",
        "closing_summary['Sentiment'] = closing_summary.index.to_series().apply(\n",
        "    lambda sym: detect_sentiment(df_closing[df_closing['symbol'] == sym])\n",
        ")\n",
        "\n",
        "# === Display ===\n",
        "print(\"\\n‚è≥ SMART MONEY ZONE ANALYSIS WITH SENTIMENT\")\n",
        "print(\"\\nüîÅ Opening Drive (9:15‚Äì10:00):\")\n",
        "print(opening_summary)\n",
        "\n",
        "print(\"\\nüîÅ Closing Session (14:45‚Äì15:15):\")\n",
        "print(closing_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvbOtDWmfO2P",
        "outputId": "f0f0e65e-33b5-49d5-a0e0-465eafdc25cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "‚è≥ SMART MONEY ZONE ANALYSIS WITH SENTIMENT\n",
            "\n",
            "üîÅ Opening Drive (9:15‚Äì10:00):\n",
            "            total_volume   Sentiment\n",
            "symbol                              \n",
            "1.1!540614     308581567  ‚öñÔ∏è Neutral\n",
            "1.1!531395      29447138  ‚öñÔ∏è Neutral\n",
            "1.1!511700      24605206  ‚öñÔ∏è Neutral\n",
            "1.1!511557      19984580  ‚öñÔ∏è Neutral\n",
            "1.1!506642      19560054  ‚öñÔ∏è Neutral\n",
            "1.1!505336      15645878  ‚öñÔ∏è Neutral\n",
            "1.1!511012       3075990   üìâ Bearish\n",
            "1.1!512591       2275248  ‚öñÔ∏è Neutral\n",
            "1.1!517554       2080586  ‚öñÔ∏è Neutral\n",
            "1.1!524632       1723244  ‚öñÔ∏è Neutral\n",
            "\n",
            "üîÅ Closing Session (14:45‚Äì15:15):\n",
            "            total_volume   Sentiment\n",
            "symbol                              \n",
            "1.1!511700       4074456  ‚öñÔ∏è Neutral\n",
            "1.1!531395       3762176  ‚öñÔ∏è Neutral\n",
            "1.1!506642       3624649  ‚öñÔ∏è Neutral\n",
            "1.1!500389       2878862  ‚öñÔ∏è Neutral\n",
            "1.1!505336       1758443  ‚öñÔ∏è Neutral\n",
            "1.1!511557        968810  ‚öñÔ∏è Neutral\n",
            "1.1!540614        743519  ‚öñÔ∏è Neutral\n",
            "1.1!511012        513404  ‚öñÔ∏è Neutral\n",
            "1.1!524174        355666  ‚öñÔ∏è Neutral\n",
            "1.1!524632        238171  ‚öñÔ∏è Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "df['time'] = df['ltt'].dt.time\n",
        "\n",
        "# === Filter Pre-Open Window: 09:00‚Äì09:15 ===\n",
        "preopen_start = pd.to_datetime(\"09:00:00\").time()\n",
        "preopen_end = pd.to_datetime(\"09:15:00\").time()\n",
        "df_preopen = df[(df['time'] >= preopen_start) & (df['time'] < preopen_end)].copy()\n",
        "\n",
        "# === Compute Sentiment Metrics per Symbol ===\n",
        "summary = df_preopen.groupby('symbol').agg(\n",
        "    total_bQty=('bQty', 'sum'),\n",
        "    total_sQty=('sQty', 'sum'),\n",
        "    avg_price=('last', 'mean'),\n",
        "    first_price=('last', 'first'),\n",
        "    last_price=('last', 'last'),\n",
        "    total_volume=('ltq', 'sum')\n",
        ")\n",
        "\n",
        "summary['gap_percent'] = ((summary['last_price'] - summary['first_price']) / summary['first_price']) * 100\n",
        "summary['demand_ratio'] = summary['total_bQty'] / (summary['total_sQty'] + 1)\n",
        "\n",
        "def classify_sentiment(row):\n",
        "    if row['gap_percent'] > 0.5 and row['demand_ratio'] > 1.5:\n",
        "        return \"üìà Bullish\"\n",
        "    elif row['gap_percent'] < -0.5 and row['demand_ratio'] < 0.7:\n",
        "        return \"üìâ Bearish\"\n",
        "    return \"‚öñÔ∏è Neutral\"\n",
        "\n",
        "summary['sentiment'] = summary.apply(classify_sentiment, axis=1)\n",
        "summary = summary.sort_values(by='total_volume', ascending=False).head(20)\n",
        "\n",
        "# === Display ===\n",
        "print(\"\\nüïí PRE-OPEN SENTIMENT FROM TICK DATA (9:00‚Äì9:15)\")\n",
        "print(summary[['gap_percent', 'demand_ratio', 'total_volume', 'sentiment']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48oIoTCjgAPx",
        "outputId": "a0088164-304c-4643-90e8-5dbde3cb7c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üïí PRE-OPEN SENTIMENT FROM TICK DATA (9:00‚Äì9:15)\n",
            "            gap_percent  demand_ratio  total_volume   sentiment\n",
            "symbol                                                         \n",
            "1.1!533090    -2.479339  1.781933e+01       6556396  ‚öñÔ∏è Neutral\n",
            "1.1!531723     0.000000  4.798863e+00       3500311  ‚öñÔ∏è Neutral\n",
            "1.1!531205    -8.333333  1.532280e+00       3103776  ‚öñÔ∏è Neutral\n",
            "1.1!517554     0.000000  2.771252e+01       2855399  ‚öñÔ∏è Neutral\n",
            "1.1!524661    -0.360360  3.855660e-05       1546857  ‚öñÔ∏è Neutral\n",
            "1.1!532368     0.000000  1.062476e-07       1186555  ‚öñÔ∏è Neutral\n",
            "1.1!532822    -0.891720  1.545588e+00        515149  ‚öñÔ∏è Neutral\n",
            "1.1!523277     0.000000  8.913450e-01        363384  ‚öñÔ∏è Neutral\n",
            "1.1!532627     0.132159  2.751975e+00        306563  ‚öñÔ∏è Neutral\n",
            "1.1!532215    -5.640485  9.002506e-02        252724   üìâ Bearish\n",
            "1.1!530095     0.000000  1.074194e-02        175362  ‚öñÔ∏è Neutral\n",
            "1.1!503641    -6.185567  5.365723e-02        162677   üìâ Bearish\n",
            "1.1!512441     0.000000  4.956364e+02        155488  ‚öñÔ∏è Neutral\n",
            "1.1!507685     1.259398  1.152399e+01        135949   üìà Bullish\n",
            "1.1!533122    21.280000  7.874437e+00        116385   üìà Bullish\n",
            "1.1!505343     0.000000  1.808816e+00        115647  ‚öñÔ∏è Neutral\n",
            "1.1!530557     0.000000  1.245311e+00         54688  ‚öñÔ∏è Neutral\n",
            "1.1!531930     0.000000  1.296020e+03         54244  ‚öñÔ∏è Neutral\n",
            "1.1!513337     0.000000  1.666667e+01         43490  ‚öñÔ∏è Neutral\n",
            "1.1!507878     0.123153  4.043866e-02         30500  ‚öñÔ∏è Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# === Convert numeric columns ===\n",
        "# Include all columns used in calculations that should be numeric\n",
        "numeric_cols = ['open', 'last', 'high', 'low', 'change', 'bPrice', 'bQty', 'sPrice',\n",
        "                'sQty', 'ltq', 'avgPrice', 'quotes', 'ttq', 'totalBuyQt', 'totalSellQ',\n",
        "                'ttv', 'VolumeC', 'OI', 'CHNGOI', 'lowerCktLm', 'upperCktLm', 'close']\n",
        "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Drop duplicates and sort after numeric conversion\n",
        "df = df.drop_duplicates().sort_values(by=['symbol', 'ltt'])\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "df = df[df['ltt'].notnull()]\n",
        "\n",
        "\n",
        "# === Feature Engineering ===\n",
        "def analyze_symbol(df_sym):\n",
        "    df_sym = df_sym.set_index('ltt').copy()\n",
        "    # Ensure columns used in calculations are numeric\n",
        "    numeric_cols_sym = ['last', 'bQty', 'sQty', 'ltq', 'ttv', 'high', 'low', 'VolumeC']\n",
        "    df_sym[numeric_cols_sym] = df_sym[numeric_cols_sym].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "    df_sym['delta_price'] = df_sym['last'].diff()\n",
        "    df_sym['rolling_bQty'] = df_sym['bQty'].rolling(30).mean()\n",
        "    df_sym['rolling_sQty'] = df_sym['sQty'].rolling(30).mean()\n",
        "    df_sym['rolling_ltq'] = df_sym['ltq'].rolling(30).mean()\n",
        "    df_sym['rolling_price'] = df_sym['last'].rolling(30).mean()\n",
        "    # Handle potential division by zero in order_imbalance\n",
        "    df_sym['order_imbalance'] = df_sym['rolling_bQty'] / (df_sym['rolling_sQty'] + df_sym['rolling_bQty']).replace(0, np.nan)\n",
        "\n",
        "    # Handle potential division by zero in vwap and ensure sum is numeric\n",
        "    ttv_cumsum = df_sym['ttv'].cumsum()\n",
        "    ltq_cumsum = df_sym['ltq'].cumsum()\n",
        "    df_sym['vwap'] = ttv_cumsum / (ltq_cumsum + 1).replace(0, np.nan)\n",
        "\n",
        "\n",
        "    df_sym['volume_spike'] = df_sym['ltq'] > df_sym['rolling_ltq'] * 2\n",
        "    df_sym['price_above_vwap'] = df_sym['last'] > df_sym['vwap']\n",
        "\n",
        "    # Score system\n",
        "    score = 0\n",
        "    if df_sym['order_imbalance'].mean() > 1.5:\n",
        "        score += 1\n",
        "    if df_sym['price_above_vwap'].mean() > 0.6:\n",
        "        score += 1\n",
        "    if df_sym['volume_spike'].sum() > 5:\n",
        "        score += 1\n",
        "    if df_sym['delta_price'].mean() > 0:\n",
        "        score += 1\n",
        "\n",
        "    if score >= 3:\n",
        "        sentiment = \"üìà Strong Bullish\"\n",
        "    elif score == 2:\n",
        "        sentiment = \"‚öñÔ∏è Mixed to Bullish\"\n",
        "    elif score == 1:\n",
        "        sentiment = \"‚ö†Ô∏è Weak\"\n",
        "    else:\n",
        "        sentiment = \"üìâ Bearish\"\n",
        "\n",
        "    return {\n",
        "        \"symbol\": df_sym['symbol'].iloc[0],\n",
        "        \"score\": score,\n",
        "        \"sentiment\": sentiment,\n",
        "        \"imbalance\": df_sym['order_imbalance'].mean(),\n",
        "        \"avg_delta_price\": df_sym['delta_price'].mean()\n",
        "    }\n",
        "\n",
        "result = []\n",
        "for symbol in df['symbol'].unique():\n",
        "    df_sym = df[df['symbol'] == symbol].copy()\n",
        "    if len(df_sym) < 60: continue\n",
        "    result.append(analyze_symbol(df_sym))\n",
        "\n",
        "summary = pd.DataFrame(result)\n",
        "summary = summary.sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "print(\"\\nüß† TICK-BASED MARKET STRATEGY ANALYSIS\")\n",
        "print(summary[['symbol', 'score', 'sentiment', 'imbalance', 'avg_delta_price']].head(20))\n",
        "\n",
        "# Composite Sentiment\n",
        "strong_bullish = (summary['sentiment'] == 'üìà Strong Bullish').sum()\n",
        "bearish = (summary['sentiment'] == 'üìâ Bearish').sum()\n",
        "\n",
        "print(f\"\\n‚úÖ Strong Bullish Symbols: {strong_bullish}\")\n",
        "print(f\"‚ùå Bearish Symbols: {bearish}\")\n",
        "\n",
        "if strong_bullish > bearish * 1.5:\n",
        "    print(\"üìä Final Market View: STRONG BULLISH BIAS for tomorrow\")\n",
        "elif bearish > strong_bullish * 1.5:\n",
        "    print(\"üìä Final Market View: STRONG BEARISH BIAS for tomorrow\")\n",
        "else:\n",
        "    print(\"üìä Final Market View: MIXED or RANGE-BOUND sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2J1hp8GhLiw",
        "outputId": "92aaf055-c11f-4087-c03c-a9a7bce31462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üß† TICK-BASED MARKET STRATEGY ANALYSIS\n",
            "         symbol  score            sentiment  imbalance  avg_delta_price\n",
            "196  1.1!500464      3     üìà Strong Bullish   0.612190         0.166667\n",
            "585  1.1!514440      3     üìà Strong Bullish   0.971475         0.359679\n",
            "720  1.1!523367      2  ‚öñÔ∏è Mixed to Bullish   0.464392         0.000417\n",
            "721  1.1!523369      2  ‚öñÔ∏è Mixed to Bullish   0.277202         0.348880\n",
            "691  1.1!522195      2  ‚öñÔ∏è Mixed to Bullish   0.557687         0.359284\n",
            "693  1.1!522217      2  ‚öñÔ∏è Mixed to Bullish   0.420586         0.031695\n",
            "694  1.1!522229      2  ‚öñÔ∏è Mixed to Bullish   0.828505         0.047704\n",
            "719  1.1!523323      2  ‚öñÔ∏è Mixed to Bullish   0.597045         0.046154\n",
            "378  1.1!506414      2  ‚öñÔ∏è Mixed to Bullish   0.899961         0.013043\n",
            "380  1.1!506525      2  ‚öñÔ∏è Mixed to Bullish   0.117880         0.089259\n",
            "381  1.1!506528      2  ‚öñÔ∏è Mixed to Bullish   0.324290        33.395349\n",
            "382  1.1!506579      2  ‚öñÔ∏è Mixed to Bullish   0.522274         0.004040\n",
            "385  1.1!506605      2  ‚öñÔ∏è Mixed to Bullish   0.451976        19.784711\n",
            "354  1.1!505790      2  ‚öñÔ∏è Mixed to Bullish   0.505575         1.650039\n",
            "355  1.1!505800      2  ‚öñÔ∏è Mixed to Bullish   0.386192         1.667063\n",
            "356  1.1!505827      2  ‚öñÔ∏è Mixed to Bullish   0.733030         3.210938\n",
            "696  1.1!522241      2  ‚öñÔ∏è Mixed to Bullish   0.577539         0.515068\n",
            "648  1.1!519552      2  ‚öñÔ∏è Mixed to Bullish   0.476582         0.007429\n",
            "717  1.1!523301      2  ‚öñÔ∏è Mixed to Bullish   0.478594         4.215363\n",
            "716  1.1!523283      2  ‚öñÔ∏è Mixed to Bullish   0.276057         0.961932\n",
            "\n",
            "‚úÖ Strong Bullish Symbols: 2\n",
            "‚ùå Bearish Symbols: 27\n",
            "üìä Final Market View: STRONG BEARISH BIAS for tomorrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "df = df[df['ltt'].notnull()].sort_values(by=['symbol', 'ltt'])\n",
        "\n",
        "# === Strategy Engine ===\n",
        "def analyze_symbol(df_sym):\n",
        "    df_sym = df_sym.set_index('ltt').copy()\n",
        "\n",
        "    # Explicitly convert columns to numeric within the function\n",
        "    numeric_cols_sym = ['open', 'last', 'high', 'low', 'bPrice', 'bQty', 'sPrice', 'sQty',\n",
        "                        'ltq', 'ttv', 'VolumeC', 'change'] # Added 'change'\n",
        "    df_sym[numeric_cols_sym] = df_sym[numeric_cols_sym].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "    df_sym['delta_price'] = df_sym['last'].diff()\n",
        "    df_sym['cumulative_delta'] = (df_sym['bQty'] - df_sym['sQty']).cumsum()\n",
        "    df_sym['rolling_bQty'] = df_sym['bQty'].rolling(30).mean()\n",
        "    df_sym['rolling_sQty'] = df_sym['sQty'].rolling(30).mean()\n",
        "    df_sym['rolling_ltq'] = df_sym['ltq'].rolling(30).mean()\n",
        "    df_sym['order_imbalance'] = df_sym['rolling_bQty'] / (df_sym['rolling_sQty'] + 1)\n",
        "    df_sym['vwap'] = df_sym['ttv'].cumsum() / (df_sym['ltq'].cumsum() + 1)\n",
        "    df_sym['price_above_vwap'] = df_sym['last'] > df_sym['vwap']\n",
        "    df_sym['delta_divergence'] = df_sym['delta_price'] * df_sym['cumulative_delta']\n",
        "    df_sym['speed_tape'] = df_sym['ltq'].diff().abs() > df_sym['rolling_ltq'] * 1.5\n",
        "\n",
        "    # Smart Score\n",
        "    score = 0\n",
        "    if df_sym['order_imbalance'].mean() > 1.5:\n",
        "        score += 1  # Order Imbalance\n",
        "    if df_sym['price_above_vwap'].mean() > 0.6:\n",
        "        score += 1  # VWAP Reclaim\n",
        "    if df_sym['delta_divergence'].mean() > 0:\n",
        "        score += 1  # Delta Divergence\n",
        "    if df_sym['speed_tape'].sum() > 5:\n",
        "        score += 1  # Speed of Tape\n",
        "\n",
        "    if score == 4:\n",
        "        sentiment = \"üöÄ Institutional Buy Setup\"\n",
        "    elif score == 3:\n",
        "        sentiment = \"üìà High Confidence Bullish\"\n",
        "    elif score == 2:\n",
        "        sentiment = \"‚öñÔ∏è Cautious / Mixed\"\n",
        "    elif score == 1:\n",
        "        sentiment = \"‚ö†Ô∏è Weak Signal\"\n",
        "    else:\n",
        "        sentiment = \"üìâ Likely Institutional Selling\"\n",
        "\n",
        "    return {\n",
        "        \"symbol\": df_sym['symbol'].iloc[0],\n",
        "        \"score\": score,\n",
        "        \"sentiment\": sentiment,\n",
        "        \"imbalance\": df_sym['order_imbalance'].mean(),\n",
        "        \"divergence\": df_sym['delta_divergence'].mean(),\n",
        "        \"speed_tape_hits\": df_sym['speed_tape'].sum()\n",
        "    }\n",
        "\n",
        "# === Run Analysis ===\n",
        "results = []\n",
        "for symbol in df['symbol'].unique():\n",
        "    df_sym = df[df['symbol'] == symbol].copy()\n",
        "    if len(df_sym) >= 60:\n",
        "        results.append(analyze_symbol(df_sym))\n",
        "\n",
        "summary = pd.DataFrame(results).sort_values(by='score', ascending=False)\n",
        "\n",
        "# === Output ===\n",
        "print(\"\\nüè¶ SMART INSTITUTIONAL MODEL v2 RESULTS:\")\n",
        "print(summary[['symbol', 'score', 'sentiment', 'imbalance', 'divergence', 'speed_tape_hits']].head(25))\n",
        "\n",
        "print(\"\\nüìä Sentiment Summary:\")\n",
        "print(summary['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P2AIur8kzNw",
        "outputId": "54f03cc9-4a79-4c16-9662-f615f02663d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üè¶ SMART INSTITUTIONAL MODEL v2 RESULTS:\n",
            "          symbol  score                  sentiment  imbalance   divergence  \\\n",
            "4     1.1!500012      3  üìà High Confidence Bullish   5.223558   163.215084   \n",
            "1151  1.1!543929      3  üìà High Confidence Bullish   1.527578     2.572685   \n",
            "738   1.1!523610      3  üìà High Confidence Bullish   1.610901    24.476221   \n",
            "740   1.1!523630      3  üìà High Confidence Bullish   1.759281    20.318619   \n",
            "742   1.1!523648      3  üìà High Confidence Bullish   4.584750    43.638150   \n",
            "746   1.1!523696      3  üìà High Confidence Bullish   1.958507    38.397597   \n",
            "752   1.1!523792      3  üìà High Confidence Bullish   1.533290    18.637609   \n",
            "753   1.1!523828      3  üìà High Confidence Bullish  22.702062    33.948913   \n",
            "38    1.1!500096      3  üìà High Confidence Bullish   2.234532    79.786827   \n",
            "44    1.1!500108      3  üìà High Confidence Bullish   1.567137     8.169625   \n",
            "45    1.1!500109      3  üìà High Confidence Bullish   2.217545   360.578948   \n",
            "48    1.1!500113      3  üìà High Confidence Bullish   1.765335   126.801796   \n",
            "19    1.1!500048      3  üìà High Confidence Bullish   1.534011   241.349904   \n",
            "21    1.1!500052      3  üìà High Confidence Bullish  15.628189  1305.868973   \n",
            "23    1.1!500059      3  üìà High Confidence Bullish   2.084343    16.625432   \n",
            "723   1.1!523373      3  üìà High Confidence Bullish   2.396888    28.654088   \n",
            "715   1.1!523277      3  üìà High Confidence Bullish   1.557452  3510.454125   \n",
            "719   1.1!523323      3  üìà High Confidence Bullish   2.070710     4.809172   \n",
            "754   1.1!523838      3  üìà High Confidence Bullish   2.752021   507.848288   \n",
            "757   1.1!523850      3  üìà High Confidence Bullish  38.049271   891.149359   \n",
            "767   1.1!524174      3  üìà High Confidence Bullish   3.156020     2.996622   \n",
            "769   1.1!524208      3  üìà High Confidence Bullish   2.002928     7.951111   \n",
            "1121  1.1!542760      3  üìà High Confidence Bullish   3.191543    85.091809   \n",
            "50    1.1!500116      3  üìà High Confidence Bullish   1.837886    28.219830   \n",
            "52    1.1!500119      3  üìà High Confidence Bullish   1.700333     8.931694   \n",
            "\n",
            "      speed_tape_hits  \n",
            "4                 100  \n",
            "1151               11  \n",
            "738                32  \n",
            "740                58  \n",
            "742                 9  \n",
            "746                11  \n",
            "752                10  \n",
            "753                11  \n",
            "38                 68  \n",
            "44                165  \n",
            "45                257  \n",
            "48                230  \n",
            "19                188  \n",
            "21                 55  \n",
            "23                  7  \n",
            "723                 8  \n",
            "715                22  \n",
            "719                12  \n",
            "754                50  \n",
            "757                13  \n",
            "767                74  \n",
            "769                85  \n",
            "1121              233  \n",
            "50                257  \n",
            "52                 27  \n",
            "\n",
            "üìä Sentiment Summary:\n",
            "sentiment\n",
            "‚öñÔ∏è Cautious / Mixed               520\n",
            "‚ö†Ô∏è Weak Signal                    333\n",
            "üìà High Confidence Bullish         235\n",
            "üìâ Likely Institutional Selling     66\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === Path to your ZIP file ===\n",
        "zip_path = \"18-07-2025_0.zip\"  # Ensure it's in the same folder or provide full path\n",
        "extract_to = \"extracted\"\n",
        "\n",
        "# === Create folder if needed ===\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "# === Extract all files ===\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "# === List extracted files ===\n",
        "print(f\"‚úÖ Extracted to: {extract_to}\")\n",
        "print(\"üìÑ Files:\")\n",
        "for file in os.listdir(extract_to):\n",
        "    print(\" -\", file)\n",
        "\n",
        "\n",
        "# === üîÑ Load and Combine All Market Files ===\n",
        "folder = \"extracted\"  # Or specify full path\n",
        "files = glob.glob(os.path.join(folder, \"18-07-2025_*.txt\"))\n",
        "\n",
        "columns = [\n",
        "    \"symbol\", \"open\", \"last\", \"high\", \"low\", \"change\", \"bPrice\", \"bQty\", \"sPrice\", \"sQty\",\n",
        "    \"ltq\", \"avgPrice\", \"quotes\", \"ttq\", \"totalBuyQt\", \"totalSellQ\", \"ttv\", \"trend\",\n",
        "    \"lowerCktLm\", \"upperCktLm\", \"ltt\", \"close\", \"exchange\", \"stock_name\", \"VolumeC\", \"OI\",\n",
        "    \"CHNGOI\", \"product_type\", \"expiry_date\", \"strike_price\"\n",
        "]\n",
        "\n",
        "df_list = []\n",
        "for file in files:\n",
        "    df_temp = pd.read_csv(file, header=None, names=columns)\n",
        "    df_list.append(df_temp)\n",
        "\n",
        "df = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "df['ltt'] = pd.to_datetime(df['ltt'], errors='coerce')\n",
        "df = df[df['ltt'].notnull()].sort_values(by=['symbol', 'ltt'])\n",
        "\n",
        "# === Define Strategy Function ===\n",
        "def evaluate_strategies(df_sym):\n",
        "    df_sym = df_sym.set_index('ltt').copy()\n",
        "\n",
        "    # Explicitly convert columns to numeric within the function\n",
        "    numeric_cols_sym = ['open', 'last', 'high', 'low', 'bPrice', 'bQty', 'sPrice', 'sQty',\n",
        "                        'ltq', 'ttv', 'VolumeC']\n",
        "    df_sym[numeric_cols_sym] = df_sym[numeric_cols_sym].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    df_sym['delta_price'] = df_sym['last'].diff()\n",
        "    df_sym['rolling_bQty'] = df_sym['bQty'].rolling(30).mean()\n",
        "    df_sym['rolling_sQty'] = df_sym['sQty'].rolling(30).mean()\n",
        "    df_sym['rolling_ltq'] = df_sym['ltq'].rolling(30).mean()\n",
        "    df_sym['order_imbalance'] = df_sym['rolling_bQty'] / (df_sym['rolling_sQty'] + 1)\n",
        "    df_sym['vwap'] = df_sym['ttv'].cumsum() / (df_sym['ltq'].cumsum() + 1)\n",
        "    df_sym['volume_spike'] = df_sym['ltq'] > df_sym['rolling_ltq'] * 2\n",
        "    df_sym['price_above_vwap'] = df_sym['last'] > df_sym['vwap']\n",
        "\n",
        "    # Strategy Scores (1 point per satisfied condition)\n",
        "    score = 0\n",
        "    strategies = {}\n",
        "\n",
        "    # 1. Order Imbalance\n",
        "    strategies['order_imbalance'] = df_sym['order_imbalance'].mean()\n",
        "    if strategies['order_imbalance'] > 1.5:\n",
        "        score += 1\n",
        "\n",
        "    # 2. Delta Tick Logic\n",
        "    strategies['avg_delta_price'] = df_sym['delta_price'].mean()\n",
        "    if strategies['avg_delta_price'] > 0:\n",
        "        score += 1\n",
        "\n",
        "    # 3. VWAP Bounce\n",
        "    above_pct = df_sym['price_above_vwap'].mean()\n",
        "    strategies['price_above_vwap_pct'] = above_pct\n",
        "    if above_pct > 0.6:\n",
        "        score += 1\n",
        "\n",
        "    # 4. Volume Spike\n",
        "    spike_count = df_sym['volume_spike'].sum()\n",
        "    strategies['volume_spike_count'] = spike_count\n",
        "    if spike_count > 5:\n",
        "        score += 1\n",
        "\n",
        "    # 5. Time-of-day trap detection (simplified for afternoon flush)\n",
        "    df_sym['hour'] = df_sym.index.hour\n",
        "    # Ensure 'ltq' is numeric before summing\n",
        "    trap_volume = df_sym.between_time(\"14:30\", \"14:45\")[\"ltq\"].apply(pd.to_numeric, errors='coerce').sum()\n",
        "    if trap_volume < df_sym['ltq'].mean() * 15:  # Low vol in flush window\n",
        "        score += 1\n",
        "\n",
        "    # 6. Trend Confirmation\n",
        "    # Ensure 'delta_price' is numeric before calculating mean\n",
        "    if (df_sym['delta_price'].tail(60).apply(pd.to_numeric, errors='coerce') > 0).mean() > 0.7:\n",
        "        score += 1\n",
        "\n",
        "    # 7. Exploding Tape\n",
        "    # Ensure 'delta_price' and 'last' are numeric\n",
        "    explosive_moves = df_sym['delta_price'].apply(pd.to_numeric, errors='coerce').abs() > df_sym['last'].apply(pd.to_numeric, errors='coerce').mean() * 0.003\n",
        "    if explosive_moves.sum() > 10:\n",
        "        score += 1\n",
        "\n",
        "    # 8. Smart Signal Combo\n",
        "    if score >= 5:\n",
        "        sentiment = \"üìà Strong Bullish\"\n",
        "    elif score >= 3:\n",
        "        sentiment = \"‚öñÔ∏è Mixed to Bullish\"\n",
        "    elif score == 2:\n",
        "        sentiment = \"‚ö†Ô∏è Weak\"\n",
        "    else:\n",
        "        sentiment = \"üìâ Bearish\"\n",
        "\n",
        "    strategies['score'] = score\n",
        "    strategies['sentiment'] = sentiment\n",
        "    strategies['symbol'] = df_sym['symbol'].iloc[0]\n",
        "    return strategies\n",
        "\n",
        "# === Run on All Symbols ===\n",
        "results = []\n",
        "for symbol in df['symbol'].unique():\n",
        "    df_sym = df[df['symbol'] == symbol].copy()\n",
        "    if len(df_sym) >= 60:\n",
        "        result = evaluate_strategies(df_sym)\n",
        "        results.append(result)\n",
        "\n",
        "summary = pd.DataFrame(results).sort_values(by=\"score\", ascending=False)\n",
        "\n",
        "# === Display Top ===\n",
        "print(\"\\nüéØ COMPOSITE STRATEGY RESULT:\")\n",
        "print(summary[['symbol', 'score', 'sentiment', 'order_imbalance', 'avg_delta_price']].head(20))\n",
        "\n",
        "# === Final Sentiment Summary ===\n",
        "print(\"\\nüìä Sentiment Count:\")\n",
        "print(summary['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M8-JgB8hx9P",
        "outputId": "2ae0a797-59cc-4630-edd4-42979e592625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted to: extracted\n",
            "üìÑ Files:\n",
            " - 18-07-2025_0.txt\n",
            "\n",
            "üéØ COMPOSITE STRATEGY RESULT:\n",
            "          symbol  score         sentiment  order_imbalance  avg_delta_price\n",
            "803   1.1!524717      5  üìà Strong Bullish         1.912149         4.903226\n",
            "436   1.1!508980      5  üìà Strong Bullish         4.264507         0.110867\n",
            "822   1.1!526193      5  üìà Strong Bullish         2.132829         0.213529\n",
            "438   1.1!509048      5  üìà Strong Bullish         6.368147         0.149804\n",
            "570   1.1!514175      5  üìà Strong Bullish         1.802400         0.000853\n",
            "440   1.1!509055      5  üìà Strong Bullish         1.642920         0.000814\n",
            "969   1.1!531746      5  üìà Strong Bullish        11.305515         0.070365\n",
            "447   1.1!509486      5  üìà Strong Bullish         7.148245         1.124427\n",
            "418   1.1!507828      5  üìà Strong Bullish         2.876359         0.002974\n",
            "377   1.1!506405      5  üìà Strong Bullish         3.912447         0.000881\n",
            "1048  1.1!532740      5  üìà Strong Bullish         1.616080         0.240180\n",
            "378   1.1!506414      5  üìà Strong Bullish        49.863449         0.013043\n",
            "284   1.1!503663      5  üìà Strong Bullish         2.246925         0.000156\n",
            "472   1.1!511333      5  üìà Strong Bullish         1.545246         0.541593\n",
            "937   1.1!531161      5  üìà Strong Bullish         8.088113         0.063672\n",
            "918   1.1!530655      5  üìà Strong Bullish         2.672347         1.533557\n",
            "152   1.1!500337      5  üìà Strong Bullish         2.928928         0.270860\n",
            "548   1.1!513361      5  üìà Strong Bullish     23850.341636         0.000719\n",
            "905   1.1!530365      5  üìà Strong Bullish         1.937565         0.028680\n",
            "550   1.1!513401      5  üìà Strong Bullish         2.335233         0.273026\n",
            "\n",
            "üìä Sentiment Count:\n",
            "sentiment\n",
            "‚öñÔ∏è Mixed to Bullish    678\n",
            "‚ö†Ô∏è Weak                278\n",
            "üìà Strong Bullish       104\n",
            "üìâ Bearish               94\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}